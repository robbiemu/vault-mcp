# Example configuration for agentic mode (requires LLM)
# This configuration demonstrates how to run the server in agentic mode
# where chunks are rewritten by an LLM agent for enhanced context

[paths]
vault_dir = "/path/to/your/obsidian-vault"
database_dir = "./chroma_db"
type = "Obsidian"

[prefix_filter]
allowed_prefixes = [
  "Project Documentation",
  "Meeting Notes",
  "Research"
]

[indexing]
chunk_size = 512
chunk_overlap = 64
quality_threshold = 0.75
enable_quality_filter = false

[watcher]
enabled = true
debounce_seconds = 2

[server]
host = "127.0.0.1"
api_port = 8000
mcp_port = 8081

[embedding_model]
provider = "sentence_transformers"
model_name = "all-MiniLM-L6-v2"

[retrieval]
# Agentic mode: use LLM rewrite agent (high quality, slower)
mode = "agentic"

[generation_model]
# Required for agentic mode - the server will fail to start without this
model_name = "gpt-4o-mini"

[generation_model.parameters]
temperature = 0.3
max_tokens = 2000

# Alternative local model example:
# [generation_model]
# model_name = "ollama/llama3"
# [generation_model.parameters]
# temperature = 0.5
# max_tokens = 1024
